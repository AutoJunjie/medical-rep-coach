import os # Import os to access environment variables
from dotenv import load_dotenv # æ–°å¢: å¯¼å…¥ load_dotenv
from strands import Agent
from strands.models.openai import OpenAIModel # æ–°å¢: å¯¼å…¥ OpenAIModel
from .tools import scenario_tool, objection_tool, eval_tool
from strands_tools import use_llm

load_dotenv() # æ–°å¢: åœ¨è„šæœ¬æ—©æœŸåŠ è½½ .env æ–‡ä»¶

class PharmaRepCoachAgent:
    def __init__(self):
        bedrock_model_id = os.getenv("BEDROCK_MODEL_ID")
        openai_api_key = os.getenv("OPENAI_API_KEY") # æ–°å¢: è·å– OpenAI API Key
        openai_base_url = os.getenv("OPENAI_BASE_URL") # æ–°å¢: è·å– OpenAI Base URL
        
        agent_kwargs = {
            "tools": [scenario_tool, objection_tool, eval_tool, use_llm],
            "system_prompt": "ä½ æ˜¯ä¸€ä¸ªåŒ»è¯ä»£è¡¨åŸ¹è®­åè°ƒå‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·è¾“å…¥åè°ƒåœºæ™¯ç”Ÿæˆã€åŒ»ç”Ÿäº’åŠ¨å’ŒåŸ¹è®­è¯„ä¼°ã€‚"
        }
        
        # ä¿®æ”¹: ä¼˜å…ˆä½¿ç”¨ OpenAIï¼Œç„¶å Bedrockï¼Œæœ€åé»˜è®¤
        if openai_api_key and openai_base_url:
            agent_kwargs["model"] = OpenAIModel(
                client_args={
                    "api_key": openai_api_key,
                    "base_url": openai_base_url,
                },
                model_id=os.getenv("OPENAI_MODEL_ID", "deepseek-ai/DeepSeek-R1"), # å…è®¸é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æ¨¡å‹IDï¼Œé»˜è®¤ä¸º Qwen/Qwen3-32B
                params={
                    "max_tokens": int(os.getenv("OPENAI_MAX_TOKENS", 1500)), # ç¡®ä¿æ˜¯æ•´æ•°
                    "temperature": float(os.getenv("OPENAI_TEMPERATURE", 0.7)),
                }
            )
            print("INFO: Using OpenAI model.")
        elif bedrock_model_id:
            agent_kwargs["model"] = bedrock_model_id
            # model_provider defaults to "bedrock" if not set, which is desired.
            # AWS_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY are picked up by AWS SDK from env.
            print(f"INFO: Using Bedrock model: {bedrock_model_id}.")
        else:
            print("INFO: Using default Strands Agent model.")

        self.strands_agent = Agent(**agent_kwargs)
        self.current_mode = "waiting_for_start"  # waiting_for_start, doctor_interaction, final_summary
        self.doctor_persona = None  # å­˜å‚¨åŒ»ç”Ÿè§’è‰²ä¿¡æ¯ (name, opening_line, characteristics)
        self.conversation_log = []  # å­˜å‚¨å¯¹è¯å†å² (speaker, utterance)

    def _get_doctor_system_prompt(self) -> str:
        if not self.doctor_persona or 'name' not in self.doctor_persona:
            return "ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸´åºŠåŒ»ç”Ÿã€‚è¯·ä»¥ä¸“ä¸šã€æœ‰æ—¶ç•¥å¸¦æŒ‘æˆ˜æ€§çš„è¯­æ°”ä¸åŒ»è¯ä»£è¡¨äº’åŠ¨ã€‚ç¡®ä¿ä½ çš„å›ç­”ç¬¦åˆåŒ»å­¦ä¸“ä¸šçŸ¥è¯†å’Œå¸¸è§çš„ä¸´åºŠæƒ…æ™¯ã€‚"
        
        name = self.doctor_persona.get('name', 'åŒ»ç”Ÿ')
        specialty = self.doctor_persona.get('specialty', 'ç›¸å…³ç§‘å®¤')
        prompt = f"ä½ æ˜¯ä¸€ä½åå« {name} çš„{specialty}åŒ»ç”Ÿã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸åŒ»è¯ä»£è¡¨è¿›è¡Œè§’è‰²æ‰®æ¼”å¯¹è¯ã€‚è¯·æ ¹æ®ä½ çš„ä¸“ä¸šèƒŒæ™¯å’Œå½“å‰å¯¹è¯æƒ…å¢ƒè¿›è¡Œå›åº”ã€‚"
        if 'characteristics' in self.doctor_persona:
            prompt += f" ä½ çš„èƒŒæ™¯ä¿¡æ¯ï¼š{self.doctor_persona['characteristics']}ã€‚"
        prompt += " è¯·ç¡®ä¿ä½ çš„å‘è¨€è‡ªç„¶ã€ä¸“ä¸šï¼Œå¹¶èƒ½æ¨åŠ¨å¯¹è¯æœ‰æ•ˆè¿›è¡Œã€‚"
        return prompt

    def handle_message(self, user_input: str) -> list[str]:
        responses = []
        self.conversation_log.append(("User", user_input))

        if self.current_mode == "waiting_for_start":
            if ("è¯å“" in user_input and "ç§‘å®¤" in user_input and 
                ("start" in user_input.lower() or "å¼€å§‹" in user_input)):
                responses.append("System: æ­£åœ¨ç”ŸæˆåŒ»ç”Ÿåœºæ™¯â€¦")
                try:
                    if "semaglutide" in user_input.lower() and "endocrinology" in user_input.lower():
                        self.doctor_persona = {
                            "name": "æä¼Ÿ", "specialty": "å†…åˆ†æ³Œç§‘",
                            "opening_line": "â€œä½ å¥½ï¼Œæˆ‘æ˜¯æä¼Ÿä¸»ä»»ï¼Œæœ€è¿‘é—¨è¯Šé‡Œè‚¥èƒ–åˆå¹¶ 2 å‹ç³–å°¿ç—…çš„æ‚£è€…è¶Šæ¥è¶Šå¤šã€‚ä½ ä»¬å¸ç¾æ ¼é²è‚½æœ‰å“ªäº›æ–°ç‰ˆæ•°æ®ï¼Ÿâ€",
                            "characteristics": "ç”·Â·45 å²Â·ä¸»ä»»åŒ»å¸ˆÂ·å‘¨å¤„æ–¹é‡â‰ˆ25 æ”¯"
                        }
                    else:
                         self.doctor_persona = {
                            "name": "ç‹åŒ»ç”Ÿ", "specialty": "ç›¸å…³ç§‘å®¤",
                            "opening_line": "â€œä½ å¥½ï¼Œå…³äºä½ æåˆ°çš„è¯å“ï¼Œè¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹æ•°æ®å’Œè¯æ®ã€‚â€",
                            "characteristics": "ç»éªŒä¸°å¯Œï¼Œå…³æ³¨è¯ç‰©çš„å®é™…ä¸´åºŠä»·å€¼ã€‚"
                        }
                    
                    self.current_mode = "doctor_interaction"
                    doctor_display_name = self.doctor_persona.get('name', 'åŒ»ç”Ÿ')
                    responses.append(f"Doctor {doctor_display_name} â–¶ {self.doctor_persona['opening_line']}")
                    if self.doctor_persona.get('characteristics'):
                        responses.append(f"System     â–¶ ã€åŒ»ç”Ÿæ¡£æ¡ˆã€‘{self.doctor_persona['characteristics']}")
                    self.conversation_log.append((f"Doctor {doctor_display_name}", self.doctor_persona['opening_line']))

                except Exception as e:
                    responses.append(f"System: æŠ±æ­‰ï¼Œç”Ÿæˆåœºæ™¯æ—¶å‡ºé”™: {str(e)}")
                    self.current_mode = "waiting_for_start"
                return responses
            else:
                responses.append('System: è¯·æä¾›è¯å“ã€ç§‘å®¤ã€éš¾åº¦ä¿¡æ¯å¹¶åŒ…å«"Start"æˆ–"å¼€å§‹"ä»¥å¯åŠ¨ã€‚ä¾‹å¦‚ï¼š"è¯å“: Semaglutideï¼›ç§‘å®¤: Endocrinologyï¼›éš¾åº¦: Basicã€‚ç‚¹å‡»ã€Startã€‘"')
                return responses

        elif self.current_mode == "doctor_interaction":
            responses.append("Coach: æ­£åœ¨è¯„ä¼°æ‚¨çš„å›ç­”â€¦")
            try:
                doctor_last_utterance = self.conversation_log[-2][1] if len(self.conversation_log) >= 2 else self.doctor_persona.get('opening_line', '')
                eval_prompt = f"ä½œä¸ºåŒ»è¯é”€å”®åŸ¹è®­æ•™ç»ƒï¼Œè¯·é’ˆå¯¹åŒ»ç”Ÿåˆšæ‰æ‰€è¯´çš„{doctor_last_utterance}ï¼Œè¯„ä¼°åŒ»è¯ä»£è¡¨çš„ä»¥ä¸‹å›ç­”ï¼š{user_input}ã€‚è¯·ç»™å‡ºè¯„åˆ†ï¼ˆä¾‹å¦‚X/100ï¼‰ã€åˆè§„æ€§ï¼ˆä¾‹å¦‚ğŸŸ¢æˆ–ğŸ”´ï¼‰ä»¥åŠå…·ä½“çš„äº®ç‚¹å’Œæ”¹è¿›å»ºè®®ã€‚"
                
                coach_feedback = self.strands_agent(eval_prompt)
                responses.append(f"Coach      â–¶ {coach_feedback}")
                self.conversation_log.append(("Coach", coach_feedback))
            except Exception as e:
                responses.append(f"Coach: è¯„ä¼°æ—¶å‡ºé”™: {str(e)}")

            if "ç»“æŸè®­ç»ƒ" in user_input or "end training" in user_input.lower():
                self.current_mode = "final_summary"
                responses.append("System: æ­£åœ¨ç”Ÿæˆæ€»ç»“æŠ¥å‘Šâ€¦")
                try:
                    summary_prompt = f"ä½œä¸ºåŒ»è¯é”€å”®åŸ¹è®­æ•™ç»ƒï¼Œè¯·å¯¹ä»¥ä¸‹å®Œæ•´çš„å¯¹è¯è®°å½•è¿›è¡Œæ€»ç»“æ€§è¯„ä¼°ã€‚å†…å®¹åº”åŒ…æ‹¬æ•´ä½“è¡¨ç°è¯„åˆ†ã€ä¸»è¦ä¼˜åŠ¿ã€å…³é”®æ”¹è¿›é¢†åŸŸï¼Œä»¥åŠå¯èƒ½çš„é›·è¾¾å›¾æ•°æ®ç‚¹ï¼ˆä¾‹å¦‚ï¼šå­¦æœ¯æ€§ã€æ²Ÿé€šæŠ€å·§ã€å¼‚è®®å¤„ç†ã€åˆè§„æ€§ç­‰ç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦ç»™ä¸€ä¸ªåˆ†æ•°ï¼‰ã€‚å¯¹è¯è®°å½•å¦‚ä¸‹ï¼š\n"
                    for speaker, utterance in self.conversation_log:
                        summary_prompt += f"{speaker}: {utterance}\n"
                    
                    final_summary = self.strands_agent(summary_prompt)
                    responses.append(f"Summary    â–¶\n{final_summary}")
                    self.conversation_log.append(("Summary", final_summary))
                    
                    self.current_mode = "waiting_for_start"
                    self.doctor_persona = None
                except Exception as e:
                    responses.append(f"System: ç”Ÿæˆæ€»ç»“æŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}")
                return responses

            try:
                doctor_system_prompt_text = self._get_doctor_system_prompt()
                
                context_for_doctor_list = []
                for log_speaker, log_utterance in reversed(self.conversation_log):
                    if log_speaker.startswith("Doctor") or log_speaker == "User":
                        context_for_doctor_list.append(f"{log_speaker}: {log_utterance}")
                    if len(context_for_doctor_list) >= 4:
                        break
                context_for_doctor = "\n".join(reversed(context_for_doctor_list))
                
                next_doctor_llm_prompt = (
                    f"è¿™æ˜¯æœ€è¿‘çš„å¯¹è¯å†å²:\n{context_for_doctor}\n\n"
                    f"ç°åœ¨è½®åˆ°ä½  ({self.doctor_persona.get('name', 'åŒ»ç”Ÿ')}) å›åº”ã€‚ä½ å¯ä»¥ç»§ç»­ä¹‹å‰çš„å¯¹è¯ï¼Œæˆ–è€…é’ˆå¯¹ä»£è¡¨çš„å‘è¨€æå‡ºä¸€ä¸ªç›¸å…³çš„ä¸´åºŠé—®é¢˜æˆ–å¸¸è§çš„é¡¾è™‘/å¼‚è®®ï¼ˆä¾‹å¦‚å…³äºè¯ç‰©æ•ˆæœã€å‰¯ä½œç”¨ã€ä»·æ ¼ã€æ‚£è€…ä¾ä»æ€§ç­‰ï¼‰ã€‚è¯·ç”Ÿæˆä½ çš„ä¸‹ä¸€å¥å¯¹è¯ã€‚"
                )
                
                if hasattr(self.strands_agent, 'tool') and hasattr(self.strands_agent.tool, 'use_llm'):
                    doctor_next_line_data = self.strands_agent.tool.use_llm(
                        prompt=next_doctor_llm_prompt,
                        system_prompt=doctor_system_prompt_text
                    )
                    if isinstance(doctor_next_line_data, dict) and 'content' in doctor_next_line_data and \
                       isinstance(doctor_next_line_data['content'], list) and len(doctor_next_line_data['content']) > 0 and \
                       'text' in doctor_next_line_data['content'][0]:
                        doctor_next_line = str(doctor_next_line_data['content'][0]['text'])
                    else:
                        doctor_next_line = str(doctor_next_line_data)
                else:
                    original_prompt = self.strands_agent.system_prompt
                    self.strands_agent.system_prompt = doctor_system_prompt_text
                    doctor_next_line = str(self.strands_agent(next_doctor_llm_prompt))
                    self.strands_agent.system_prompt = original_prompt

                tool_marker = ""
                objection_keywords = ["ä»·æ ¼", "è´¹ç”¨", "å¤ªè´µ", "æ•ˆæœ", "ç–—æ•ˆ", "å‰¯ä½œç”¨", "ä¸è‰¯ååº”", "ä¾ä»æ€§"]
                if any(keyword in doctor_next_line for keyword in objection_keywords):
                    tool_marker = " _ObjectionTool_"

                doctor_display_name = self.doctor_persona.get('name', 'åŒ»ç”Ÿ')
                responses.append(f"Doctor {doctor_display_name} â–¶ {doctor_next_line}{tool_marker}")
                self.conversation_log.append((f"Doctor {doctor_display_name}", doctor_next_line))
            except Exception as e:
                responses.append(f"Doctor: ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {str(e)}")
            return responses
        
        elif self.current_mode == "final_summary":
            responses.append("System: åŸ¹è®­å·²ç»“æŸã€‚å¦‚éœ€å¼€å§‹æ–°çš„åŸ¹è®­ï¼Œè¯·æŒ‰æ ¼å¼æç¤ºå¼€å§‹ã€‚")
            self.current_mode = "waiting_for_start"
            self.doctor_persona = None
            return responses
        
        return responses

def demonstrate_chat_flow():
    print("æ¬¢è¿æ¥åˆ° PharmaRep Coachï¼")
    coach_agent = PharmaRepCoachAgent()

    chat_interactions = [
        ("User", "è¯å“: Semaglutideï¼›ç§‘å®¤: Endocrinologyï¼›éš¾åº¦: Basicã€‚ç‚¹å‡»ã€Startã€‘"),
        ("User", "ä¸»ä»»å¥½ï¼æœ€æ–° SELECT ç ”ç©¶æ˜¾ç¤ºå£æœå¸ç¾æ ¼é²è‚½å¯æ˜¾è‘—é™ä½ MACE å¤åˆç»ˆç‚¹ï¼Œå¿ƒè¡€ç®¡è·ç›Šæ˜ç¡®..."),
        ("User", "å…³äºä»·æ ¼ï¼Œæˆ‘ä»¬æœ‰ç›¸åº”çš„æ‚£è€…æ´åŠ©é¡¹ç›®ï¼ŒåŒæ—¶é•¿æœŸæ¥çœ‹ï¼Œè‰¯å¥½çš„è¡€ç³–å’Œä½“é‡æ§åˆ¶èƒ½å‡å°‘å¹¶å‘ç—‡æ²»ç–—è´¹ç”¨ï¼Œæ€»ä½“æ˜¯ç»æµçš„ã€‚"),
        ("User", "æˆ‘ä»¬æœ‰è¯¦ç»†çš„å‰‚é‡é€’å¢æŒ‡å¯¼æ–¹æ¡ˆï¼Œå‰4å‘¨ä½¿ç”¨0.25mgèµ·å§‹å‰‚é‡ï¼Œéšåé€æ­¥å¢åŠ åˆ°ç»´æŒå‰‚é‡ï¼Œèƒ½å¾ˆå¥½åœ°ç®¡ç†èƒƒè‚ é“ååº”ï¼Œæé«˜æ‚£è€…è€å—æ€§å’Œä¾ä»æ€§ã€‚"),
        ("User", "å¥½çš„ä¸»ä»»ï¼Œæˆ‘ä¼šæŠŠSELECTç ”ç©¶æ‘˜è¦å’Œå‰‚é‡é€’å¢æ–¹æ¡ˆå‘åˆ°æ‚¨çš„é‚®ç®±ï¼Œå¹¶å‘æ‚¨é¢„çº¦ä¸‹å‘¨è¿›è¡Œä¸€æ¬¡è¯¦ç»†çš„å­¦æœ¯æ‹œè®¿ã€‚"),
        ("User", "ç‚¹å‡»ã€ç»“æŸè®­ç»ƒã€‘")
    ]

    for speaker, message in chat_interactions:
        print(f"\n{speaker:10} â–¶ {message}")
        if speaker == "User":
            agent_responses = coach_agent.handle_message(message)
            for res in agent_responses:
                # Standard prefixes for display
                doctor_prefix_display = f"{'Doctor':<10} ({coach_agent.doctor_persona.get('name', '') if coach_agent.doctor_persona else ''})"
                coach_prefix_display = f"{'Coach':<10}"
                summary_prefix_display = f"{'Summary':<10}"

                if res.startswith("Doctor"):
                    parts = res.split('â–¶', 1)
                    message_content = parts[1].strip() if len(parts) > 1 else res
                    if message_content.startswith("Doctor: "): # Strip "Doctor: " if it's an error message
                        message_content = message_content[len("Doctor: "):].strip()
                    print(f"{doctor_prefix_display} â–¶ {message_content}")
                
                elif res.startswith("Coach"):
                    parts = res.split('â–¶', 1)
                    message_content = parts[1].strip() if len(parts) > 1 else res
                    if message_content.startswith("Coach: "): # Strip "Coach: " if it's an error message
                        message_content = message_content[len("Coach: "):].strip()
                    print(f"{coach_prefix_display} â–¶ {message_content}")

                elif res.startswith("Summary"):
                    parts = res.split('â–¶', 1)
                    message_content = parts[1].strip() if len(parts) > 1 else res
                    if message_content.startswith("Summary: "): # Strip "Summary: " if it's an error message
                        message_content = message_content[len("Summary: "):].strip()
                    print(f"{summary_prefix_display} â–¶ {message_content}")
                
                else: # System messages (e.g., "System: ...", "System     â–¶ ...")
                    print(res)
            
if __name__ == "__main__":
    demonstrate_chat_flow()

    # å¦‚æœéœ€è¦äº¤äº’å¼æµ‹è¯•:
    # print("\n=== è¿›å…¥äº¤äº’æµ‹è¯•æ¨¡å¼ (è¾“å…¥ 'exit' ç»“æŸ) ===")
    # agent_interactive = PharmaRepCoachAgent()
    # while True:
    #     user_input_interactive = input("User       â–¶ ")
    #     if user_input_interactive.lower() == "exit":
    #         break
    #     responses_interactive = agent_interactive.handle_message(user_input_interactive)
    #     for r_interactive in responses_interactive:
    #         print(r_interactive) 